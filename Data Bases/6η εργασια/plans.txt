/* The result, before creating an intex for the query 1: 
EXPLAIN ANALYZE SELECT "Host".id, COUNT(*) FROM "Copy_Listing", "Host"
WHERE "Host".id = "Copy_Listing".host_id
GROUP BY "Host".id;
*/

QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"HashAggregate  (cost=3273.70..3337.33 rows=6363 width=12) (actual time=25.670..27.426 rows=6363 loops=1)"
"  Group Key: "Host".id"
"  ->  Hash Join  (cost=255.26..3215.99 rows=11541 width=4) (actual time=3.388..20.992 rows=11541 loops=1)"
"        Hash Cond: ("Copy_Listing".host_id = "Host".id)"
"        ->  Seq Scan on "Copy_Listing"  (cost=0.00..2930.41 rows=11541 width=4) (actual time=0.005..11.634 rows=11541 loops=1)"
"        ->  Hash  (cost=175.73..175.73 rows=6363 width=4) (actual time=3.367..3.368 rows=6363 loops=1)"
"              Buckets: 8192  Batches: 1  Memory Usage: 288kB"
"              ->  Index Only Scan using "Host_pkey" on "Host"  (cost=0.28..175.73 rows=6363 width=4) (actual time=0.009..1.609 rows=6363 loops=1)"
"                    Heap Fetches: 0"
"Planning time: 0.193 ms"
"Execution time: 28.700 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/*The result, after creating an intex for the query 1:
EXPLAIN ANALYZE SELECT "Host".id, COUNT(*) FROM "Copy_Listing", "Host"
WHERE "Host".id = "Copy_Listing".host_id
GROUP BY "Host".id;
*/

QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"HashAggregate  (cost=652.69..716.32 rows=6363 width=12) (actual time=16.024..17.758 rows=6363 loops=1)"
"  Group Key: "Host".id"
"  ->  Hash Join  (cost=255.55..594.98 rows=11541 width=4) (actual time=3.380..11.871 rows=11541 loops=1)"
"        Hash Cond: ("Copy_Listing".host_id = "Host".id)"
"        ->  Index Only Scan using listing_idx on "Copy_Listing"  (cost=0.29..309.40 rows=11541 width=4) (actual time=0.012..2.944 rows=11541 loops=1)"
"              Heap Fetches: 0"
"        ->  Hash  (cost=175.73..175.73 rows=6363 width=4) (actual time=3.353..3.353 rows=6363 loops=1)"
"              Buckets: 8192  Batches: 1  Memory Usage: 288kB"
"              ->  Index Only Scan using "Host_pkey" on "Host"  (cost=0.28..175.73 rows=6363 width=4) (actual time=0.008..1.614 rows=6363 loops=1)"
"                    Heap Fetches: 0"
"Planning time: 0.224 ms"
"Execution time: 18.973 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* Query 1: w/out index: 28.700 ms; w/index: 18.973 ms 
With the index there is an improvement in the execution time, because the listing_idx is used to save the host_id at the table Copy_Listing.
So there is no need for the query to scan the whole Copy_Listing table to find the host_id, it uses the index to get it right away. And that's why there is a big improvement in the time.  
*/

===========================================================================================================================================
/* The result, before creating an intex for the query 2:
EXPLAIN ANALYZE SELECT id, price FROM "Copy_Listing", "Price"
WHERE guests_included > 5 AND price > 40;
*/

QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Nested Loop  (cost=0.29..20234.56 rows=1569576 width=8) (actual time=0.025..1539.769 rows=2469774 loops=1)"
"  ->  Index Only Scan using "Copy_Listings_pkey" on "Copy_Listing"  (cost=0.29..309.40 rows=11541 width=4) (actual time=0.013..3.581 rows=11541 loops=1)"
"        Heap Fetches: 0"
"  ->  Materialize  (cost=0.00..305.80 rows=136 width=4) (actual time=0.000..0.046 rows=214 loops=11541)"
"        ->  Seq Scan on "Price"  (cost=0.00..305.12 rows=136 width=4) (actual time=0.008..1.183 rows=214 loops=1)"
"              Filter: ((guests_included > 5) AND (price > 40))"
"              Rows Removed by Filter: 11327"
"Planning time: 0.131 ms"
"Execution time: 2004.984 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/*The result, after creating an intex for the query 2:
EXPLAIN ANALYZE SELECT id, price FROM "Copy_Listing", "Price"
WHERE guests_included > 5 AND price > 40;
*/

QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Nested Loop  (cost=0.43..19939.62 rows=1569576 width=8) (actual time=0.028..1478.313 rows=2469774 loops=1)"
"  ->  Index Only Scan using "Copy_Listings_pkey" on "Copy_Listing"  (cost=0.29..309.40 rows=11541 width=4) (actual time=0.018..3.448 rows=11541 loops=1)"
"        Heap Fetches: 0"
"  ->  Materialize  (cost=0.14..10.86 rows=136 width=4) (actual time=0.000..0.043 rows=214 loops=11541)"
"        ->  Index Only Scan using price_idx on "Price"  (cost=0.14..10.18 rows=136 width=4) (actual time=0.007..0.056 rows=214 loops=1)"
"              Heap Fetches: 0"
"Planning time: 0.128 ms"
"Execution time: 1919.640 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* Query 2: w/out index: 2004.984 ms; w/index: 1919.640 ms
By using the index price_idx, we save time because we create an index that only has the values that comply with the query's WHERE clause. That way the query doesn't need to scan the whole table and filter the values, that's why the time is way better.
*/

===========================================================================================================================================
/* The result, before creating an intex for the query 5.1: 
EXPLAIN ANALYZE SELECT "Room".listing_id, "Room".square_feet, "Price".price
FROM "Price"
FULL OUTER JOIN "Room"
ON "Price".listing_id = "Room".listing_id
WHERE "Price".price < 200;
*/

QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Hash Left Join  (cost=904.67..1210.37 rows=11210 width=11) (actual time=8.245..17.204 rows=11190 loops=1)"
"  Hash Cond: ("Price".listing_id = "Room".listing_id)"
"  ->  Seq Scan on "Price"  (cost=0.00..276.26 rows=11210 width=8) (actual time=0.005..3.346 rows=11190 loops=1)"
"        Filter: (price < 200)"
"        Rows Removed by Filter: 351"
"  ->  Hash  (cost=760.41..760.41 rows=11541 width=7) (actual time=8.219..8.219 rows=11541 loops=1)"
"        Buckets: 16384  Batches: 1  Memory Usage: 535kB"
"        ->  Seq Scan on "Room"  (cost=0.00..760.41 rows=11541 width=7) (actual time=0.002..4.650 rows=11541 loops=1)"
"Planning time: 0.234 ms"
"Execution time: 19.283 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/*The result, after creating an intex for the query 5.1:
EXPLAIN ANALYZE SELECT "Room".listing_id, "Room".square_feet, "Price".price
FROM "Price"
FULL OUTER JOIN "Room"
ON "Price".listing_id = "Room".listing_id
WHERE "Price".price < 200;
*/

QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Hash Left Join  (cost=505.66..811.36 rows=11210 width=11) (actual time=6.411..15.264 rows=11190 loops=1)"
"  Hash Cond: ("Price".listing_id = "Room".listing_id)"
"  ->  Seq Scan on "Price"  (cost=0.00..276.26 rows=11210 width=8) (actual time=0.005..3.324 rows=11190 loops=1)"
"        Filter: (price < 200)"
"        Rows Removed by Filter: 351"
"  ->  Hash  (cost=361.40..361.40 rows=11541 width=7) (actual time=6.384..6.385 rows=11541 loops=1)"
"        Buckets: 16384  Batches: 1  Memory Usage: 535kB"
"        ->  Index Only Scan using room_idx on "Room"  (cost=0.29..361.40 rows=11541 width=7) (actual time=0.012..3.080 rows=11541 loops=1)"
"              Heap Fetches: 0"
"Planning time: 0.187 ms"
"Execution time: 17.361 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* Query 5.1: w/out index: 19.283 ms; w/index: 17.361 ms 
With the index there is a significant improvement in the execution time, because the room_idx is used to save the listing_id and the square_feet column at the table Romm, so there is no need for the query to scan the whole table to find those columns.
*/

===========================================================================================================================================
/* The result, before creating an intex for the query 5.2:
EXPLAIN ANALYZE SELECT "Geolocation".properties_neighbourhood, "Location".is_location_exact, "Geolocation".geometry_coordinates_0_0_60_0,"Geolocation".geometry_coordinates_0_0_50_0
FROM "Geolocation"
FULL OUTER JOIN "Location"
ON "Location".neighbourhood_cleansed = "Geolocation".properties_neighbourhood;
*/
QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Hash Full Join  (cost=9.01..390.57 rows=11541 width=40) (actual time=0.100..11.236 rows=11541 loops=1)"
"  Hash Cond: (("Location".neighbourhood_cleansed)::text = ("Geolocation".properties_neighbourhood)::text)"
"  ->  Seq Scan on "Location"  (cost=0.00..348.41 rows=11541 width=30) (actual time=0.002..2.702 rows=11541 loops=1)"
"  ->  Hash  (cost=8.45..8.45 rows=45 width=39) (actual time=0.091..0.091 rows=45 loops=1)"
"        Buckets: 1024  Batches: 1  Memory Usage: 11kB"
"        ->  Seq Scan on "Geolocation"  (cost=0.00..8.45 rows=45 width=39) (actual time=0.008..0.068 rows=45 loops=1)"
"Planning time: 0.093 ms"
"Execution time: 13.433 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* The result, after creating an intex for the query 5.2:
EXPLAIN ANALYZE SELECT "Geolocation".properties_neighbourhood, "Location".is_location_exact, "Geolocation".geometry_coordinates_0_0_60_0,"Geolocation".geometry_coordinates_0_0_50_0
FROM "Geolocation"
FULL OUTER JOIN "Location"
ON "Location".neighbourhood_cleansed = "Geolocation".properties_neighbourhood;
*/
QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Hash Full Join  (cost=9.01..390.57 rows=11541 width=40) (actual time=0.086..10.397 rows=11541 loops=1)"
"  Hash Cond: (("Location".neighbourhood_cleansed)::text = ("Geolocation".properties_neighbourhood)::text)"
"  ->  Seq Scan on "Location"  (cost=0.00..348.41 rows=11541 width=30) (actual time=0.002..2.612 rows=11541 loops=1)"
"  ->  Hash  (cost=8.45..8.45 rows=45 width=39) (actual time=0.077..0.077 rows=45 loops=1)"
"        Buckets: 1024  Batches: 1  Memory Usage: 11kB"
"        ->  Seq Scan on "Geolocation"  (cost=0.00..8.45 rows=45 width=39) (actual time=0.008..0.056 rows=45 loops=1)"
"Planning time: 0.111 ms"
"Execution time: 12.484 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* Query 5.2: w/out index: 13.433 ms; w/index: 12.484 ms 
With the index there an improvement in the execution time, because we are using two indexes, one on the Location table that saves the column neighbourhood_cleansed and one Geolocation table that saves the column properties_neighbourhood. With those indexes both tables don't have to scan the whole table to find the needed columns for the FULL OUTER JOIN, that's why we save time.
*/
===========================================================================================================================================
/* The result, before creating an intex for the query 5.3:
EXPLAIN ANALYZE SELECT "Location".city, COUNT("Host".id) AS "numberOfHosts"
FROM "Host"
INNER JOIN "Location"
ON "Location".neighbourhood = "Host".neighbourhood
GROUP BY "Location".city
HAVING COUNT("Host".id)>15;
*/
QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"HashAggregate  (cost=58939.77..58940.86 rows=109 width=15) (actual time=1862.961..1862.999 rows=104 loops=1)"
"  Group Key: "Location".city"
"  Filter: (count("Host".id) > 15)"
"  Rows Removed by Filter: 4"
"  ->  Hash Join  (cost=618.17..37296.75 rows=2885737 width=11) (actual time=5.156..881.318 rows=2897158 loops=1)"
"        Hash Cond: (("Location".neighbourhood)::text = ("Host".neighbourhood)::text)"
"        ->  Seq Scan on "Location"  (cost=0.00..348.41 rows=11541 width=16) (actual time=0.006..3.163 rows=11541 loops=1)"
"        ->  Hash  (cost=538.63..538.63 rows=6363 width=13) (actual time=5.136..5.136 rows=4923 loops=1)"
"              Buckets: 8192  Batches: 1  Memory Usage: 282kB"
"              ->  Seq Scan on "Host"  (cost=0.00..538.63 rows=6363 width=13) (actual time=0.003..3.145 rows=6363 loops=1)"
"Planning time: 0.155 ms"
"Execution time: 1863.065 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* The result, after creating an intex for the query 5.3:
EXPLAIN ANALYZE SELECT "Location".city, COUNT("Host".id) AS "numberOfHosts"
FROM "Host"
INNER JOIN "Location"
ON "Location".neighbourhood = "Host".neighbourhood
GROUP BY "Location".city
HAVING COUNT("Host".id)>15;
*/
QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"HashAggregate  (cost=58608.87..58609.96 rows=109 width=15) (actual time=1814.610..1814.643 rows=104 loops=1)"
"  Group Key: "Location".city"
"  Filter: (count("Host".id) > 15)"
"  Rows Removed by Filter: 4"
"  ->  Hash Join  (cost=287.26..36965.84 rows=2885737 width=11) (actual time=3.841..823.067 rows=2897158 loops=1)"
"        Hash Cond: (("Location".neighbourhood)::text = ("Host".neighbourhood)::text)"
"        ->  Seq Scan on "Location"  (cost=0.00..348.41 rows=11541 width=16) (actual time=0.007..3.129 rows=11541 loops=1)"
"        ->  Hash  (cost=207.73..207.73 rows=6363 width=13) (actual time=3.821..3.821 rows=4923 loops=1)"
"              Buckets: 8192  Batches: 1  Memory Usage: 282kB"
"              ->  Index Only Scan using host_idx on "Host"  (cost=0.28..207.73 rows=6363 width=13) (actual time=0.031..1.771 rows=6363 loops=1)"
"                    Heap Fetches: 0"
"Planning time: 0.196 ms"
"Execution time: 1814.712 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* Query 5.3: w/out index:1863.065 ms; w/index: 1814.712 ms 
With the index there an improvement in the execution time, because we are using two indexes, one on the Location table that saves the column neighbourhood and one Host table that saves the columns id, neighbourhood. With those indexes both tables don't have to scan the whole table to find the needed columns for the INNER JOIN, that's why we save time.
*/
===========================================================================================================================================
/* The result, before creating an intex for the query 5.4:
EXPLAIN ANALYZE SELECT "Room".listing_id, "Location".neighbourhood, "Room".security_deposit
FROM "Room"
INNER JOIN "Location"
ON "Location".listing_id = "Room".listing_id
WHERE "Room".security_deposit = '$150.00' AND "Location".neighbourhood = 'Plaka';
*/
QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Hash Join  (cost=793.12..1174.25 rows=39 width=19) (actual time=3.070..4.989 rows=44 loops=1)"
"  Hash Cond: ("Location".listing_id = "Room".listing_id)"
"  ->  Seq Scan on "Location"  (cost=0.00..377.26 rows=1472 width=13) (actual time=0.008..1.624 rows=1472 loops=1)"
"        Filter: ((neighbourhood)::text = 'Plaka'::text)"
"        Rows Removed by Filter: 10069"
"  ->  Hash  (cost=789.26..789.26 rows=309 width=10) (actual time=2.994..2.994 rows=309 loops=1)"
"        Buckets: 1024  Batches: 1  Memory Usage: 22kB"
"        ->  Seq Scan on "Room"  (cost=0.00..789.26 rows=309 width=10) (actual time=0.012..2.885 rows=309 loops=1)"
"              Filter: ((security_deposit)::text = '$150.00'::text)"
"              Rows Removed by Filter: 11232"
"Planning Time: 0.227 ms"
"Execution Time: 5.025 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* The result, after creating an intex for the query 5.4:
EXPLAIN ANALYZE SELECT "Room".listing_id, "Location".neighbourhood, "Room".security_deposit
FROM "Room"
INNER JOIN "Location"
ON "Location".listing_id = "Room".listing_id
WHERE "Room".security_deposit = '$150.00' AND "Location".neighbourhood = 'Plaka';
*/
QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Hash Join  (cost=60.78..316.04 rows=39 width=19) (actual time=0.308..1.329 rows=44 loops=1)"
"  Hash Cond: ("Location".listing_id = "Room".listing_id)"
"  ->  Bitmap Heap Scan on "Location"  (cost=36.01..287.41 rows=1472 width=13) (actual time=0.086..0.764 rows=1472 loops=1)"
"        Recheck Cond: ((neighbourhood)::text = 'Plaka'::text)"
"        Heap Blocks: exact=230"
"        ->  Bitmap Index Scan on location_idx2  (cost=0.00..35.64 rows=1472 width=0) (actual time=0.061..0.061 rows=1472 loops=1)"
"  ->  Hash  (cost=20.91..20.91 rows=309 width=10) (actual time=0.183..0.183 rows=309 loops=1)"
"        Buckets: 1024  Batches: 1  Memory Usage: 22kB"
"        ->  Index Only Scan using room_idx2 on "Room"  (cost=0.27..20.91 rows=309 width=10) (actual time=0.014..0.091 rows=309 loops=1)"
"              Heap Fetches: 0"
"Planning time: 0.237 ms"
"Execution time: 1.367 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* Query 5.4: w/out index: 5.025 ms; w/index: 1.367 ms 
With the index there is a significant improvement in the execution time, because the room_idx2 is used to save the values that comply with the WHERE clause of the security_deposit, also we are using an index in the Location table for the same reason. That way we are saving time from the query since there is no need to search the whole table to filter the values.
*/

===========================================================================================================================================
/* The result, before creating an intex for the query 5.5:
EXPLAIN ANALYZE SELECT COUNT("Copy_Review".listing_id) AS "numberOfReviews", "Price".price
FROM "Copy_Review"
INNER JOIN "Price"
ON "Price".listing_id = "Copy_Review".listing_id
GROUP BY "Price".price
HAVING COUNT("Copy_Review".id) > 100
ORDER BY "numberOfReviews" DESC;
*/
QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Sort  (cost=24475.29..24475.99 rows=282 width=12) (actual time=583.085..583.111 rows=137 loops=1)"
"  Sort Key: (count("Copy_Review".listing_id)) DESC"
"  Sort Method: quicksort  Memory: 31kB"
"  ->  Finalize GroupAggregate  (cost=24455.35..24463.81 rows=282 width=12) (actual time=582.713..583.033 rows=137 loops=1)"
"        Group Key: "Price".price"
"        Filter: (count("Copy_Review".id) > 100)"
"        Rows Removed by Filter: 94"
"        ->  Sort  (cost=24455.35..24456.76 rows=564 width=20) (actual time=582.706..582.813 rows=534 loops=1)"
"              Sort Key: "Price".price"
"              Sort Method: quicksort  Memory: 66kB"
"              ->  Gather  (cost=24370.36..24429.58 rows=564 width=20) (actual time=581.735..584.094 rows=534 loops=1)"
"                    Workers Planned: 2"
"                    Workers Launched: 2"
"                    ->  Partial HashAggregate  (cost=23370.36..23373.18 rows=282 width=20) (actual time=577.070..577.127 rows=178 loops=3)"
"                          Group Key: "Price".price"
"                          ->  Hash Join  (cost=391.67..22075.87 rows=172598 width=12) (actual time=19.499..439.646 rows=138078 loops=3)"
"                                Hash Cond: ("Copy_Review".listing_id = "Price".listing_id)"
"                                ->  Parallel Seq Scan on "Copy_Review"  (cost=0.00..19310.98 rows=172598 width=8) (actual time=0.025..161.457 rows=138078 loops=3)"
"                                ->  Hash  (cost=247.41..247.41 rows=11541 width=8) (actual time=19.421..19.421 rows=11541 loops=3)"
"                                      Buckets: 16384  Batches: 1  Memory Usage: 579kB"
"                                      ->  Seq Scan on "Price"  (cost=0.00..247.41 rows=11541 width=8) (actual time=0.012..5.793 rows=11541 loops=3)"
"Planning time: 0.135 ms"
"Execution time: 584.795 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* The result, after creating an intex for the query 5.5:
EXPLAIN ANALYZE SELECT COUNT("Copy_Review".listing_id) AS "numberOfReviews", "Price".price
FROM "Copy_Review"
INNER JOIN "Price"
ON "Price".listing_id = "Copy_Review".listing_id
GROUP BY "Price".price
HAVING COUNT("Copy_Review".id) > 100
ORDER BY "numberOfReviews" DESC;
*/
QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------
"Sort  (cost=24475.29..24475.99 rows=282 width=12) (actual time=534.328..534.353 rows=137 loops=1)"
"  Sort Key: (count("Copy_Review".listing_id)) DESC"
"  Sort Method: quicksort  Memory: 31kB"
"  ->  Finalize GroupAggregate  (cost=24455.35..24463.81 rows=282 width=12) (actual time=533.966..534.276 rows=137 loops=1)"
"        Group Key: "Price".price"
"        Filter: (count("Copy_Review".id) > 100)"
"        Rows Removed by Filter: 94"
"        ->  Sort  (cost=24455.35..24456.76 rows=564 width=20) (actual time=533.958..534.061 rows=531 loops=1)"
"              Sort Key: "Price".price"
"              Sort Method: quicksort  Memory: 66kB"
"              ->  Gather  (cost=24370.36..24429.58 rows=564 width=20) (actual time=530.399..533.801 rows=531 loops=1)"
"                    Workers Planned: 2"
"                    Workers Launched: 2"
"                    ->  Partial HashAggregate  (cost=23370.36..23373.18 rows=282 width=20) (actual time=526.443..526.499 rows=177 loops=3)"
"                          Group Key: "Price".price"
"                          ->  Hash Join  (cost=391.67..22075.87 rows=172598 width=12) (actual time=16.653..411.013 rows=138078 loops=3)"
"                                Hash Cond: ("Copy_Review".listing_id = "Price".listing_id)"
"                                ->  Parallel Seq Scan on "Copy_Review"  (cost=0.00..19310.98 rows=172598 width=8) (actual time=3.135..180.308 rows=138078 loops=3)"
"                                ->  Hash  (cost=247.41..247.41 rows=11541 width=8) (actual time=13.468..13.468 rows=11541 loops=3)"
"                                      Buckets: 16384  Batches: 1  Memory Usage: 579kB"
"                                      ->  Seq Scan on "Price"  (cost=0.00..247.41 rows=11541 width=8) (actual time=0.009..7.228 rows=11541 loops=3)"
"Planning time: 0.249 ms"
"Execution time: 534.482 ms"
-------------------------------------------------------------------------------------------------------------------------------------------
/* Query 5.5: w/out index: 584.795 ms; w/index: 534.482 ms 
With the index there is an improvement in the execution time, because the price_idx2 and copyReview_idx are used to save columns needed for the query. That way we are saving time from the query since there is no need to search the whole table to find the needed columns.
*/